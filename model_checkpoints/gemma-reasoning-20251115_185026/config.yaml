data:
  augment: false
  augmentation_ratio: 0.1
  eval_file: data/synthetic_reasoning_set.jsonl
  max_eval_samples: 10
  max_train_samples: 50
  prompt_template: 'Answer the following question. Show your reasoning step by step,
    then provide your final answer.


    Question: {question}


    Format your response as:

    <reasoning>

    Your step-by-step reasoning here

    </reasoning>

    <answer>

    Your final answer here

    </answer>

    '
  train_file: data/synthetic_reasoning_set.jsonl
deterministic: true
hardware:
  compile: true
  device: cpu
  gradient_checkpointing: true
  mixed_precision: false
  num_workers: 4
  offload_to_cpu: false
model:
  base_model: gemma2-2b
  do_sample: true
  max_answer_tokens: 128
  max_new_tokens: 512
  max_reasoning_tokens: 256
  model_path: gemma/
  temperature: 0.7
  tokenizer_path: gemma/
  top_k: 50
  top_p: 0.9
multi_session:
  checkpoint_to_resume: null
  enabled: false
  kaggle_model_name: null
  session_id: 1
output:
  answer_tag: <answer>
  format_penalty_weight: 0.5
  output_dir: model_checkpoints/
  reasoning_tag: <reasoning>
  required_format: true
  run_name: gemma-reasoning-{timestamp}
reward:
  config_file: configs/reward_config.yaml
  reward_model: gemma2-2b
seed: 42
training:
  batch_size: 2
  clip_range: 0.2
  eval_steps: 10
  eval_strategy: steps
  evaluation_metric: reward_score
  gradient_accumulation_steps: 4
  group_size: 2
  grpo_config: configs/grpo_config.yaml
  kl_coefficient: 0.1
  learning_rate: 5e-6
  load_best_model_at_end: true
  logging_dir: logs/
  logging_steps: 5
  lr_scheduler: cosine
  max_grad_norm: 1.0
  num_epochs: 2
  report_to: tensorboard
  save_steps: 500
  save_strategy: steps
  save_total_limit: 3
  warmup_ratio: 0.1
  weight_decay: 0.01
